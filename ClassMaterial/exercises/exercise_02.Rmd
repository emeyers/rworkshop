---
title: "Day 2 morning exercises"
output:
  pdf_document: default
  html_document:
    df_print: paged
---




$\\$





The purpose of these exercises is to practice using `dplyr` to transform data
and `ggplot2` to visualize data.


The team that made `dplyr` and `ggplot` has also created many learning
resources. Some of them are listed below:


- [Intro to dplyr vignette](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html)
- [A conceptual overview from the dplyr home page](https://dplyr.tidyverse.org/)
- [R for Data Science is a book that discusses dplyr and ggplot](https://r4ds.had.co.nz/)





<!--  Please run the code in the  R chunk below once. This will install some
packages and download data and images needed for these exercises.  -->

```{r message=FALSE, warning = FALSE, echo = FALSE, eval = FALSE}

# makes sure you have all the packages we have used in class installed

rworkshop::download_data("freshman-15.txt")
rworkshop::download_data("forecast_ne_joined.rda")
rworkshop::download_image("grumpy_cat.jpg")

```





<!-- The R chunk below sets some parameters that will be used in the rest of the document. Please ignore it and do not modify it. -->
```{r message=FALSE, warning=FALSE, tidy=TRUE, echo = FALSE}

library(knitr)
library(latex2exp)
library(dplyr)
library(gapminder)
library(ggplot2)
library(ggridges)

# turn off some dplyr message
options(dplyr.summarise.inform = FALSE)

options(scipen=999)

opts_chunk$set(tidy.opts=list(width.cutoff=60)) 
set.seed(230)  # set the random number generator to always give the same random numbers
    
```





$\\$



   
   

## Part 1: Data transformations with dplyr


Now that COVID-19 has become more endemic, people are starting to travel on
airplanes more frequently. As I'm sure you are aware, this form of travel is
convenient because airplanes fly very fast. However, even though the airplanes
themselves are fast, their scheduled departure times are often delayed, which
used to make people frustrated.

Let's analyze data on flights to gain insight into how best to avoid flight
delays. In particular, we will look at airplane flights that left the airports
in New York City, since these airports are some of the closest major airports to
New Haven, and we will use dplyr to do some quick explorations of the data to
see if there are some ways to potentially avoid flight delays.

To begin, let's load the data for flights leaving New York City in 2013 using
the code below. To get more information on this data set, use *? flights* (you
don't need to modify anything on the code below).

 
```{r message=FALSE, warning=FALSE}


# install.packages("nycflights13")

# get the flight delays data and load dplyr
require("nycflights13")
data(flights)
data(airlines)   # the names of the airline carriers


```



   
$\\$   
    
   
    



**Part 1.1:**  One way to avoid being delayed would be to avoid the
worst airlines. Which airline had the longest arrival delays on average, and how
long was this average delay?  Use the `airlines` data frame to figure out which
airline each carrier code corresponds to.


```{r, bad_airlines, message=FALSE, warning=FALSE}

library(dplyr)


# get the average delay for each airline








```

**Answers**:  
   
   
   
   
   
   
$\\$      





**Part 1.2:**  Flights that start off with a delay might end up
making up some time during the course of the flight. Examine whether this is
true on average by reporting relevant descriptive statistics.

Hint: we only use flights that have positive departure delay (since a flight
needs to be delayed in order to "make up time").


```{r, make_up_time, message=FALSE, warning=FALSE}







```

**Answers**: 








$\\$    
    

    

    

**Part 1.3:**  Another way to avoid flight delays would be to avoid
particularly bad times to fly. Which month of the year had the longest departure
delays? Also report which hour of the day had the longest departure delays.
Finally, report how many flights left at the hour of the day with the longest
delay and what the average delay was at that hour.

Hint: You can use `n()` within summarize to get the size of each group specified
by the call to `group_by()`.


```{r, bad_fly_time, message=FALSE, warning=FALSE}















```

**Answers**: 




    
    
$\\$    

![](grumpy_cat.jpg){width=50%}





$\\$






## Part 2: Data visualization


In the next set of exercises you will use `ggplot2` to compare different
visualizations and see which gives the clearest insights. As mentioned above, a
useful resource for ggplot and other tidyverse code is the book [R for Data
Science](https://r4ds.had.co.nz).




$\\$





**Part 2.1**: Let's start by comparing some visualizations on the
[gapminder data](https://www.gapminder.org) which contains information about
different countries in the world over time. Use `ggplot` and the `gapminder` data to
compare the GDP per capita of Japan, the United States and China. Plot a line
graph of GDP per capita as a function of the year, with each country in a
different color. Also, create a plot that compares these countries' GDP per
capita as a function of the year using facets, where the data from each country
is on a separate subplot. As always, make sure to label your axes in this plot
and in all other plots in this homework. Do you think one type of plot is better
than another in comparing these countries? Explain why.

Hint: first use the dplyr `filter()` function to get the subset of data you
need, then plot it.


```{r gapminder, message=FALSE, warning=FALSE}


















```

**Answers**: [Explain whether you think of of these plots is more informative than the other]. 








$\\$






**Part 2.2**:  DataExpo is a Statistics event at the Joint
Statistical Meetings where different researchers compare data analysis methods
applied to a common data set. In 2018, the data set consisted of weather
predictions made between 2014 and 2017. In this exercise, let's look at the data
from this event and try to visualize the prediction accuracies for predictions
made 0 to 6 days in the future.

The code below loads a data frame called `forecast_ne_joined` that has the
prediction errors for the maximum temperature for the 9 cities in New England,
along with several other variables. First, create a new data frame called
`new_haven_preds` that has only the predictions from New Haven, and has only the
variables `cityID`, `city`, `num_days_out_prediction_made` and
`max_temp_prediction_error`. Also, convert the variable
`num_days_out_prediction_made` to a factor using the `as.factor()` function
inside of the `mutate()` function. Then use ggplot to create plots that compare
the prediction accuracy as a function of the number of days in advance that a
prediction was made using the following geoms:

1. Create a box plot using `geom_boxplot()`
2. Create a violin plot using `geom_violin()`
3. Create a joy plot using `geom_density_ridges()`

Note that the geom `geom_density_ridges()` comes from the ggridges packages that
was loaded at the top of the worksheet, and that the x and y aesthetic mapping
needs to be in the opposite order as the mapping used for the `geom_boxplot()` and
`geom_violin()` geoms.

After you created these plots, briefly discuss which plot you believe most
clearly shows how the prediction accuracy decreases as a function of days in the
future. Also, don't forget to label your axes using the `xlab()` and `ylab()`
functions.


```{r weather_predictions, message=FALSE, warning=FALSE}


# load the data that has the weather prediction errors
load('forecast_ne_joined.rda')
























```


**Answers**:








$\\$






**Part 3.2**: Create an *interesting* plot using one of the data sets
we have discussed in class or another data set you can find. Try exploring other
features of ggplot we have not discussed in class using the [ggplot cheat
sheet](https://github.com/rstudio/cheatsheets/raw/master/data-visualization.pdf).
See if you can find something interesting in the data and explain why you find
it interesting.



```{r your_viz, message=FALSE, warning=FALSE}








```


**Answers**:   








$\\$










